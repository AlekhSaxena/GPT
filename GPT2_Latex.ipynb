{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQEWm7yCjz9C"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer,TextDataset,DataCollatorForLanguageModeling,GPT2LMHeadModel, pipeline, Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "1jJrp64Olutf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "3uBdOJI9lEuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Now, you can use the file path \"/content/drive/My Drive/\" to access your Google Drive files.\n"
      ],
      "metadata": {
        "id": "WPdG6rFJlKUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/My Drive/english_to_latex.csv')\n",
        "print(data.shape)\n",
        "data.head(2)"
      ],
      "metadata": {
        "id": "Wz3UzEUXl6W7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token=tokenizer.eos_token"
      ],
      "metadata": {
        "id": "FFJnF0ufmTtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Add our Singular prompt\n",
        "CONVERSION_PROMPT='LCT\\n'\n",
        "CONVERSION_TOKEN='LaTeX:'"
      ],
      "metadata": {
        "id": "j8t-EzQIm76Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## This is training prompt that we want GPT to rcognize and learn\n",
        "\n",
        "training_examples=f'{CONVERSION_PROMPT}English: '+data['English']+ '\\n'+ CONVERSION_TOKEN+' '+ data['LaTeX']"
      ],
      "metadata": {
        "id": "jmMpS6irnOT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_examples[0])"
      ],
      "metadata": {
        "id": "ZDu_lNh_n6t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_df=pd.DataFrame({'text':training_examples})\n",
        "task_df.head(2)"
      ],
      "metadata": {
        "id": "NEs0wTWsn8Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latex_data=Dataset.from_pandas(task_df) ## Turn a pandas df into a dataset\n",
        "def preprocess(examples):\n",
        "    return tokenizer(examples['text'],truncation=True)\n",
        "\n",
        "latex_data=latex_data.map(preprocess,batched=True)\n",
        "latex_data=latex_data.train_test_split(train_size=0.8)\n"
      ],
      "metadata": {
        "id": "Oa46iFUBoyu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer,mlm=False)"
      ],
      "metadata": {
        "id": "fRG7KV7YpDjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latex_gpt2=GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "I8Dug2Xc46Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "id": "7uVe4Lz66CUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args=TrainingArguments(\n",
        "    output_dir='./gpt2_latex',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=20,\n",
        "    ##warmup_steps=len(pds_data.examples)//5,\n",
        "    logging_steps=5,\n",
        "    log_level='info',\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch'\n",
        ")"
      ],
      "metadata": {
        "id": "xwV4WUPU5c9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Trainer(\n",
        "    model=latex_gpt2,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=latex_data['train'],\n",
        "    eval_dataset=latex_data['test']\n",
        ")"
      ],
      "metadata": {
        "id": "TtxtnyLS56en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "I-B_Fmt562Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "YaxHmvhe64mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculus_data=TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='/content/drive/My Drive/calculus made easy.txt',\n",
        "    block_size=32\n",
        ")\n",
        "\n",
        "data_collator=DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,mlm=False\n",
        ")\n",
        "\n",
        "latext_gpt2=GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "training_args=TrainingArguments(\n",
        "    output_dir='/content/drive/My Drive/gpt2_calculus',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    ##warmup_steps=len(pds_data.examples)//5,\n",
        "    logging_steps=50,\n",
        "    log_level='info',\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy='steps',\n",
        "    save_strategy='steps'\n",
        ")"
      ],
      "metadata": {
        "id": "Ec3ZkA3F6-B4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer=Trainer(\n",
        "    model=latex_gpt2,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=calculus_data.examples[:int(len(calculus_data.examples)*0.8)],\n",
        "    eval_dataset=calculus_data.examples[int(len(calculus_data.examples)*0.8):]\n",
        ")"
      ],
      "metadata": {
        "id": "_EVlxc-r89bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "nQ1nfwNu9l5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "6vxRW84Z9pZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "8uuDpHu19v5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "Jq3VO0WLABXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model=GPT2LMHeadModel.from_pretrained('/content/drive/My Drive/gpt2_calculus')\n",
        "latex_generator=pipeline('text-generation',model=loaded_model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "HsXggCzXAZFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample='f of x equals integral from 0 to pi of x to the fourth power'\n",
        "conversion_text_sample=f'{CONVERSION_PROMPT}English: {text_sample}\\n{CONVERSION_TOKEN}'\n",
        "print(conversion_text_sample)"
      ],
      "metadata": {
        "id": "l8plCsnnAzzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latex_generator(conversion_text_sample,num_beams=5,early_stopping=True,temperature=0.7,\n",
        "                      max_length=len(tokenizer.encode(conversion_text_sample))+20)[0]['generated_text'])"
      ],
      "metadata": {
        "id": "1lhzX7KbB845"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args=TrainingArguments(\n",
        "    output_dir='./gpt2_latex_calculus',\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=20,\n",
        "    ##warmup_steps=len(pds_data.examples)//5,\n",
        "    logging_steps=5,\n",
        "    log_level='info',\n",
        "    load_best_model_at_end=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch'\n",
        ")\n",
        "trainer=Trainer(\n",
        "    model=loaded_model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=latex_data['train'],\n",
        "    eval_dataset=latex_data['test']\n",
        ")"
      ],
      "metadata": {
        "id": "c3VXJbmJONVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "H80GJB3XRJyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Rxbyf_uHRMuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()"
      ],
      "metadata": {
        "id": "ET4edn_eRPnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model=GPT2LMHeadModel.from_pretrained('./gpt2_latex_calculus')\n",
        "latex_generator_f=pipeline('text-generation',model=loaded_model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "-Qj_MoXCRacO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(latex_generator_f(conversion_text_sample,num_beams=5,early_stopping=True,temperature=0.7,\n",
        "                      max_length=len(tokenizer.encode(conversion_text_sample))+20)[0]['generated_text'])"
      ],
      "metadata": {
        "id": "toGf_em5Rn_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0HvWmvzR8Fi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}